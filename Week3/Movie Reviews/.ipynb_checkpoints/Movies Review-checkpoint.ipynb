{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_data = pd.read_csv('Data\\\\labeledTrainData.tsv',header=0,delimiter=\"\\t\", quoting=3)\n",
    "test_data = pd.read_csv('Data\\\\testData.tsv',header=0,delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['review'].values\n",
    "y = train_data['sentiment'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lam.Huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    \"\"\" Return a cleaned version of text\n",
    "    \"\"\"\n",
    "    # Remove HTML markup\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Save emoticons for later appending\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    # Remove any non-word character and append the emoticons,\n",
    "    # removing the nose character for standarization. Convert to lower case\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n",
    "    \n",
    "    return text\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# write a function called `tokenizer()` that split a text into list of words\n",
    "# Your code here\n",
    "def tokenizer(text):\n",
    "    res = text.split()\n",
    "    return res\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function preproc...nalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stop,\n",
    "                        tokenizer=tokenizer_porter,\n",
    "                        preprocessor=preprocessor)\n",
    "\n",
    "clf = Pipeline([('vect', tfidf),\n",
    "                ('clf', LogisticRegression(random_state=0))])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8853333333333333\n",
      "[[3293  503]\n",
      " [ 357 3347]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.87      0.88      3796\n",
      "          1       0.87      0.90      0.89      3704\n",
      "\n",
      "avg / total       0.89      0.89      0.89      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "prediction = clf.predict(X_test)\n",
    "accuracy_score = accuracy_score(y_test,prediction)\n",
    "confusion_matrix = confusion_matrix(y_test,prediction)\n",
    "classification_report = classification_report(y_test,prediction)\n",
    "print(accuracy_score)\n",
    "print(confusion_matrix)\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = test_data['review'].values\n",
    "#preds = clf.predict_proba(reviews)\n",
    "preds = clf.predict(reviews)\n",
    "\n",
    "#for i in range(len(reviews)):\n",
    "#    print(f'{test_data.id[i]} --> Negative, Positive  = {preds[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#import os\n",
    "#\n",
    "#pickle.dump(clf, open(os.path.join('data', 'MoviesReviews.pkl'), 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review  sentiment\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...          1\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...          0\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...          1\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...          1\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['sentiment'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.to_csv('Output\\\\Result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1566     2\n",
       "\"4619     2\n",
       "\"3603     2\n",
       "\"1225     2\n",
       "\"3844     2\n",
       "\"8012     2\n",
       "\"4455     2\n",
       "\"2110     2\n",
       "\"3239     2\n",
       "\"1252     2\n",
       "\"8196     2\n",
       "\"5652     2\n",
       "\"2428     2\n",
       "\"10435    2\n",
       "\"11225    2\n",
       "\"736      2\n",
       "\"11254    2\n",
       "\"10810    2\n",
       "\"8853     2\n",
       "\"11371    2\n",
       "\"9709     2\n",
       "\"11953    2\n",
       "\"3722     2\n",
       "\"2412     2\n",
       "\"5591     2\n",
       "\"2765     2\n",
       "\"2836     2\n",
       "\"4590     2\n",
       "\"1538     2\n",
       "\"10056    2\n",
       "         ..\n",
       "\"7645     2\n",
       "\"2312     2\n",
       "\"7489     2\n",
       "\"4306     2\n",
       "\"1741     2\n",
       "\"4122     2\n",
       "\"9493     2\n",
       "\"9561     2\n",
       "\"108      2\n",
       "\"12067    2\n",
       "\"12439    2\n",
       "\"11740    2\n",
       "\"7751     2\n",
       "\"2082     2\n",
       "\"8582     2\n",
       "\"7529     2\n",
       "\"2255     2\n",
       "\"608      2\n",
       "\"6338     2\n",
       "\"7448     2\n",
       "\"9893     2\n",
       "\"6799     2\n",
       "\"12033    2\n",
       "\"4684     2\n",
       "\"5918     2\n",
       "\"11068    2\n",
       "\"953      2\n",
       "\"7334     2\n",
       "\"7733     2\n",
       "\"2607     2\n",
       "Name: movie_id, Length: 12500, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['movie_id'] = test_data.id.str.split('_').str[0]\n",
    "test_data['movie_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
